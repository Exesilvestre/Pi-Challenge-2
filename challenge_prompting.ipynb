{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oLzddANOIqbvK7TieI6rtnAgV0PkpvxNVGlfcqL5\n"
     ]
    }
   ],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='492d5e7e-8ea7-4790-8b04-a167026aef0b' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "## bloque conexion a Cohere\n",
    "import cohere\n",
    "\n",
    "# co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisi√≥n\n",
    "- S√≠ntomas\n",
    "- Diagn√≥stico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "example_text =\"\"\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares./\n",
    "Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. /\n",
    "La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "example_response = {\n",
    "                      \"paciente\": {\n",
    "                        \"nombre\": \"Mar√≠a Gonz√°lez\",\n",
    "                        \"edad\": 45\n",
    "                      },\n",
    "                      \"fecha_admision\": \"2023-08-05\",\n",
    "                      \"sintomas\": [\n",
    "                        \"fatiga cr√≥nica\",\n",
    "                        \"dolores musculares\"\n",
    "                      ],\n",
    "                      \"diagnostico\": \"fibromialgia\",\n",
    "                      \"tratamiento\": [\n",
    "                        \"fisioterapia\",\n",
    "                        \"medicamentos analg√©sicos\"\n",
    "                      ]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d0a6-db5c-4eec-9f71-89e60ceaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Sof√≠a L√≥pez, de 28 a√±os, ingres√≥ al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Despu√©s de varias pruebas, se le diagnostic√≥ neumon√≠a. La pediatra responsable, Dra. Claudia Torres, indic√≥ tratamiento con antibi√≥ticos y reposo./\n",
    "La pr√≥xima evaluaci√≥n ser√° el 10 de abril.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "system_prompt = \"Sos un asistente de IA que dedicado para extraer de un texto ciertas entidades y devolverlas en formato Json\"\n",
    "def create_prompt(context):\n",
    "    prompt = f\"\"\" \n",
    "                ###\n",
    "                Instrucciones: \n",
    "                - Responde la pregunta utilizado el contexto.\n",
    "                - La respuesta debe estar estrictamente en formato JSON v√°lido.\n",
    "                - Las entidades deben ser como las del ejemplo.\n",
    "                - Si hay algun dato que no este en el contexto debes dejarlo como null en el json.\n",
    "    \n",
    "                ###\n",
    "                Contexto:\n",
    "                {context}\n",
    "    \n",
    "                ###\n",
    "                Ejemplo:\n",
    "                {example_response}\n",
    "    \n",
    "                ###\n",
    "                Pregunta:\n",
    "                Obtenga desde el contexto las entidades paciente, fecha_admision, sintomas, diagnostico y tratamiento como en el ejemplo\n",
    "    \n",
    "                \"\"\"\n",
    "    return prompt\n",
    "    \n",
    "def extract_entities(context):\n",
    "    prompt = create_prompt(text_to_analize)\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Sof√≠a L√≥pez\",\n",
      "        \"edad\": 28\n",
      "    },\n",
      "    \"fecha_admision\": \"2023-04-03\",\n",
      "    \"sintomas\": [\"fiebre alta\", \"tos persistente\"],\n",
      "    \"diagnostico\": \"neumon√≠a\",\n",
      "    \"tratamiento\": [\"antibi√≥ticos\", \"reposo\"]\n",
      "}\n",
      "{'paciente': {'nombre': 'Sof√≠a L√≥pez', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumon√≠a', 'tratamiento': ['antibi√≥ticos', 'reposo']}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import json\n",
    "llm_response = extract_entities(prompt)\n",
    "print(llm_response)\n",
    "final_result = json.loads(llm_response)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "097ee190-faca-46d8-9c11-0f8904bd1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con mas descripciones\n",
    "text_to_analize_2 = \"\"\"Javier Morales, de 35 a√±os, fue admitido en el Hospital General el 15 de mayo de 2023 debido a dolor abdominal severo y n√°useas persistentes./\n",
    "Despu√©s de realizar una ecograf√≠a, se diagnostic√≥ apendicitis aguda. El doctor encargado, Dr. Roberto S√°nchez, indic√≥ cirug√≠a de emergencia seguida de reposo absoluto./\n",
    "La pr√≥xima revisi√≥n m√©dica est√° programada para el 22 de mayo.\"\"\"\n",
    "\n",
    "text_to_analize3 = \"\"\"Ana Fern√°ndez, de 42 a√±os, lleg√≥ al Hospital San Pedro el 10 de enero de 2023 con s√≠ntomas de dolor de cabeza intenso y visi√≥n borrosa./\n",
    "Tras un examen detallado, se le diagnostic√≥ migra√±a cr√≥nica. La doctora a cargo, Dra. Mariana L√≥pez, recomend√≥ tratamiento con medicamentos espec√≠ficos y sesiones de relajaci√≥n./\n",
    "La pr√≥xima cita est√° fijada para el 17 de enero.\"\"\"\n",
    "\n",
    "text_to_analize_4 = \"\"\"Lucas Ram√≠rez, de 50 a√±os, ingres√≥ al Hospital Universitario el 20 de marzo de 2023 debido a dificultad para respirar y dolor en el pecho./\n",
    "Despu√©s de varios estudios, se diagnostic√≥ neumon√≠a bacteriana. El m√©dico tratante, Dr. Eduardo Guti√©rrez, orden√≥ tratamiento con antibi√≥ticos intravenosos y oxigenoterapia./\n",
    "La siguiente consulta est√° prevista para el 27 de marzo.\"\"\"\n",
    "\n",
    "all_texts = [text_to_analize_2, text_to_analize3, text_to_analize_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df0e72e5-3bd5-4f26-860c-340e25e72f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TEST 1\n",
      "{'paciente': {'nombre': 'Sof√≠a L√≥pez', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumon√≠a', 'tratamiento': ['antibi√≥ticos', 'reposo']}\n",
      "#### TEST 2\n",
      "{'paciente': {'nombre': 'Sof√≠a L√≥pez', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumon√≠a', 'tratamiento': ['antibi√≥ticos', 'reposo']}\n",
      "#### TEST 3\n",
      "{'paciente': {'nombre': 'Sof√≠a L√≥pez', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumon√≠a', 'tratamiento': ['antibi√≥ticos', 'reposo']}\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for test in all_texts:\n",
    "    try:\n",
    "        llm_response = extract_entities(test)\n",
    "        final_result = json.loads(llm_response)\n",
    "        print(f\"#### TEST {index}\")\n",
    "        print(final_result)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al procesar TEST {index}: {e}\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan P√©rez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): N√∫mero de tel√©fono del contacto.\n",
    "        email (str): Correo electr√≥nico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adici√≥n del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto a√±adido con √©xito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la informaci√≥n de un contacto.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Informaci√≥n del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\"\n",
    "\n",
    "functions_map = {\n",
    "    \"add_contact\": add_contact,\n",
    "    \"get_information\": get_information\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d3bed9a-d5d1-49c3-b91b-8cd23bb9c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Connects to a database to add a contact given his name, phone and email\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Add contact with this name.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Add contact with this phone number\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Add contact with this email address\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Connects a database to get a contact infromation given his name\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Retrieves contact information data the contact with that name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ddaf4d1-6ab9-4707-823d-11ada125b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "## Task and Context\n",
    "You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n",
    "You are able to interact with a contacts database.\n",
    "\n",
    "## Style Guide\n",
    "Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n",
    "\"\"\"\n",
    "add_contact_message1 = \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\" \n",
    "add_contact_message2 = \"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "search_contact_info_message = \"Cual es el Email de Juan P√©rez.?\"\n",
    "\n",
    "def create_messages(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will add the contact details provided to the database. \n",
      "\n",
      "Tool name: add_contact | Parameters: {\"email\":\"juanperez@mail.com\",\"name\":\"Juan P√©rez\",\"phone\":\"555-1234\"}\n",
      "Contacto a√±adido con √©xito.\n",
      "Final LLM Response: Contact added successfully.\n"
     ]
    }
   ],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "def llm_request(messages):\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def start_request(messages):\n",
    "    tool_content = []\n",
    "\n",
    "    # Call the model\n",
    "    response = llm_request(messages)\n",
    "    print(response.message.tool_plan, \"\\n\")\n",
    "\n",
    "    # Check if there are tool calls\n",
    "    if response.message.tool_calls:\n",
    "        for tc in response.message.tool_calls:\n",
    "            messages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})\n",
    "            # Access tool call attributes using dot notation\n",
    "            print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "            \n",
    "            # Call the suggested function\n",
    "            tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "            tool_content.append(json.dumps(tool_result))\n",
    "            messages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': tool_content}) \n",
    "            print(tool_result)\n",
    "    else:\n",
    "        print(\"No function was called.\")\n",
    "\n",
    "    # Final LLM call to summarize the results\n",
    "    final_response = llm_request(messages)\n",
    "    print(\"Final LLM Response:\", final_response.message.content[0].text)\n",
    "\n",
    "messages = create_messages(add_contact_message1)\n",
    "start_request(messages)\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ace85d2-cd00-4bd4-81e2-68113eb9f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will add the contact details to the database. \n",
      "\n",
      "Tool name: add_contact | Parameters: {\"email\":\"lucia.gomez@gmail.com\",\"name\":\"Luc√≠a G√≥mez\",\"phone\":\"555-5678\"}\n",
      "Contacto a√±adido con √©xito.\n",
      "Final LLM Response: Hecho. He guardado a Luc√≠a G√≥mez en tus contactos.\n"
     ]
    }
   ],
   "source": [
    "messages = create_messages(add_contact_message2)\n",
    "start_request(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c0a3461-981f-46ab-aded-314b016fffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search for Juan P√©rez in the database and then relay the email address to the user. \n",
      "\n",
      "Tool name: get_information | Parameters: {\"name\":\"Juan P√©rez\"}\n",
      "{'phone': '555-1234', 'email': 'juanperez@mail.com'}\n",
      "Final LLM Response: The email address for Juan P√©rez is juanperez@mail.com.\n"
     ]
    }
   ],
   "source": [
    "messages = create_messages(search_contact_info_message)\n",
    "start_request(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5edb99-ea7f-4e68-b1c2-3be0ce7d7798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instructions_lenguage = f\"\"\"\n",
    "    - Responde solo especificando el idioma en el que esta la pregunta\n",
    "    - La respuesta debe ser una sola palabra con el idioma.\n",
    "\"\"\"\n",
    "\n",
    "instructions = f\"\"\"\n",
    "    - las respuestas deben ser en base a la historia.\n",
    "    - ante la misma pregunta siempre debe responder de la misma manera.\n",
    "    - que responda en solo una oracion.\n",
    "    - el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "    - que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "    - que responda siempre en tercera persona.\n",
    "    - si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "    - Responder con 'Hakuna Matata!' al final de todas las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_prompt(instructions, pregunta, historia=\"\"):\n",
    "    prompt = f\"\"\" \n",
    "                ###\n",
    "                Instrucciones: \n",
    "                {instructions} \n",
    "                ###\n",
    "                Contexto:\n",
    "                {historia}\n",
    "    \n",
    "                ###\n",
    "                Pregunta:\n",
    "                {pregunta}\n",
    "    \n",
    "                \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "system_prompt = \"Sos un asistente de IA dedicado a responder consultas de usuarios de un amplio rango de temas. Te proveeran un contexto y el usuairo te hara preguntas sobre el mismo, en caso de poder repsonderlas debes elaborar una repsuesta de acuerdo al contexto.\"\n",
    "system_prompt1 = \"Sos un asistente de IA dedicado a responder el idioma en el que te preguntaron.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_request(messages):\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    )\n",
    "    return response.message.content[0].text\n",
    "\n",
    "def create_messages(prompt, system_prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "def determine_language(pregunta):\n",
    "    prompt = create_prompt(instructions_lenguage, pregunta)\n",
    "    messages = create_messages(prompt, system_prompt1)\n",
    "    return llm_request(messages)\n",
    "\n",
    "def generate_final_answer(pregunta, idioma):\n",
    "    final_instructions = f\"\"\"\n",
    "        {instructions}\n",
    "        - La respuesta debe estar en el idioma: {idioma}.\n",
    "    \"\"\"\n",
    "    prompt = create_prompt(final_instructions, pregunta, historia)\n",
    "    messages = create_messages(prompt, system_prompt)\n",
    "    return llm_request(messages)\n",
    "\n",
    "def history_answer(pregunta):\n",
    "    idioma = determine_language(pregunta)\n",
    "    return generate_final_answer(pregunta, idioma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b13663-c4d1-47b9-9c63-9d0015d2a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas tiene diecis√©is a√±os, una edad en la que la inocencia y la dureza de la vida se encuentran. üåæ Hakuna Matata!\n",
      "Thomas se ve obligado a cambiar su hoz por una lanza y unirse a la milicia local debido al llamado a las armas del rey, quien convoc√≥ a todos los hombres en edad de luchar para la guerra, dejando atr√°s su dura pero pac√≠fica vida de campesino. Hakuna Matata! üó°Ô∏èüåæü¶Å\n",
      "Thomas regresa al feudo con el coraz√≥n pesado, marcado por la cruda realidad de la guerra, sintiendo que la inocencia de su juventud ha sido arrebatada brutalmente, y su mirada fija en el horizonte refleja un vac√≠o y una madurez forzada. üòû Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "# respuesta\n",
    "preguntas = [\n",
    "    \"¬øCu√°l es la edad de Thomas?\",\n",
    "    \"¬øPor qu√© Thomas se ve obligado a unirse a la milicia local?\",\n",
    "    \"¬øQu√© siente Thomas despu√©s de la batalla?\",\n",
    "    \"¬øQu√© es el sistema operativo Linux?\",\n",
    "    \"¬øC√≥mo se construye un puente colgante?\"\n",
    "]\n",
    "for pregunta in preguntas:\n",
    "    print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "795f451e-6c12-4631-895f-fa6ac8f16b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas tiene diecis√©is a√±os y trabaja desde el amanecer en los campos de trigo. üåæ Hakuna Matata!\n",
      "Thomas se ve obligado a cambiar su hoz por una lanza y unirse a la milicia local debido al llamado a las armas del rey, quien convoc√≥ a todos los hombres en edad de luchar para la guerra, dejando atr√°s su dura pero pac√≠fica vida campesina. Hakuna Matata! üó°Ô∏èüåæü¶Å\n",
      "Thomas regres√≥ al feudo con el coraz√≥n pesado, marcado por la brutal realidad de la guerra, sintiendo que la inocencia de su juventud hab√≠a quedado enterrada en ese campo de batalla, junto con los ca√≠dos. üòû Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "# Chequeo de que siempre repsonde lo mismo ante las mismas preguntas\n",
    "preguntas = [\n",
    "    \"¬øCu√°l es la edad de Thomas?\",\n",
    "    \"¬øPor qu√© Thomas se ve obligado a unirse a la milicia local?\",\n",
    "    \"¬øQu√© siente Thomas despu√©s de la batalla?\",\n",
    "    \"¬øQu√© es el sistema operativo Linux?\",\n",
    "    \"¬øC√≥mo se construye un puente colgante?\"\n",
    "]\n",
    "for pregunta in preguntas:\n",
    "    print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos √∫tiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7daa9f9-e5f4-4273-8b8d-66088e816f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f3dfe3e30842e39ee0a083a241952d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eba16455e244ff3ac3b4232bde321cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bff4e6d73f748629073f71891320407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "instructions = f\"\"\"\n",
    "                - Responder con una sola oraci√≥n corta.\n",
    "                - Responder de manera positiva, con un tono entusiasta.\n",
    "                - Responder con consejos √∫tiles, como si fueras un tutor.\n",
    "                - S√© claro y conciso.\n",
    "                - La respuesta deber tener menos de 70 tokens\"\"\"\n",
    "\n",
    "system_content = \"\"\"\n",
    "        Eres un chatbot dise√±ado para ayudar y dar consejos √∫tiles.\n",
    "        Siempre debes ser positivo, con un tono entusiasta, y tus respuestas deben ser concisas y claras.\n",
    "        Tu objetivo es ayudar de manera efectiva y siempre dentro del l√≠mite de 70 tokens.\n",
    "\n",
    "    \"\"\"\n",
    "def create_prompt(instructions, pregunta):\n",
    "    prompt = f\"\"\" \n",
    "    ###\n",
    "    Instrucciones: \n",
    "    {instructions}\n",
    "    ###\n",
    "    Pregunta:\n",
    "    {pregunta}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "    \n",
    "chat_history = []\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    prompt = create_prompt(instructions, message)\n",
    "\n",
    "    relevant_history = chat_history[-3:]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content}\n",
    "    ]\n",
    "    messages.extend(relevant_history) \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt}) \n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=messages,\n",
    "        max_tokens=70\n",
    "    )\n",
    "    text_response = response.message.content[0].text\n",
    "    print(response.usage.billed_units)\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": text_response})\n",
    "    \n",
    "    return text_response\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d5bce-0189-4ecd-a06d-fcc7a81315b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d22e77e-3784-4443-8d89-a3156adca812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T√∫:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oraci√≥n corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos √∫tiles, como si fueras un tutor.\n",
      "                - S√© claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Hola como estas?\n",
      "    \n",
      "\n",
      "Chatbot: ¬°Hola! Estoy genial y listo para ayudarte con cualquier duda o desaf√≠o que tengas. ¬°Pregunta sin miedo!\n",
      "\n",
      "T√∫:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oraci√≥n corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos √∫tiles, como si fueras un tutor.\n",
      "                - S√© claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Cuales son los tres deportes mas famosos del mundo?\n",
      "    \n",
      "\n",
      "Chatbot: ¬°El f√∫tbol, el baloncesto y el tenis son deportes muy populares a nivel global y cuentan con millones de seguidores!\n",
      "\n",
      "T√∫:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oraci√≥n corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos √∫tiles, como si fueras un tutor.\n",
      "                - S√© claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Quien es el jugador mas reconocido del tenis?\n",
      "    \n",
      "\n",
      "Chatbot: ¬°Sin duda, Roger Federer es una leyenda del tenis y uno de los atletas m√°s admirados en todo el mundo!\n",
      "\n",
      "T√∫:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oraci√≥n corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos √∫tiles, como si fueras un tutor.\n",
      "                - S√© claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Cuantos grand slams gano Roger?\n",
      "    \n",
      "\n",
      "Chatbot: ¬°Roger Federer ha ganado un impresionante total de 20 t√≠tulos de Grand Slam!\n",
      "\n",
      "T√∫:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oraci√≥n corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos √∫tiles, como si fueras un tutor.\n",
      "                - S√© claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Muchas por la informacion. Y quien fue su competidor mas fuerte?\n",
      "    \n",
      "\n",
      "Chatbot: ¬°Sin duda, Rafael Nadal ha sido uno de los rivales m√°s fuertes y emblem√°ticos de Federer en su carrera!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_conversation(chat_history):\n",
    "    for message in chat_history:\n",
    "        if message['role'] == 'user':\n",
    "            print(f\"T√∫: {message['content']}\\n\")\n",
    "        elif message['role'] == 'assistant':\n",
    "            print(f\"Chatbot: {message['content']}\\n\")\n",
    "\n",
    "# Imprimir el chat\n",
    "print_conversation(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oraci√≥n corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos √∫tiles, como si fueras un tutor.\\n                - S√© claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Hola como estas?\\n    '}, {'role': 'assistant', 'content': '¬°Hola! Estoy genial y listo para ayudarte con cualquier duda o desaf√≠o que tengas. ¬°Pregunta sin miedo!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oraci√≥n corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos √∫tiles, como si fueras un tutor.\\n                - S√© claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Cuales son los tres deportes mas famosos del mundo?\\n    '}, {'role': 'assistant', 'content': '¬°El f√∫tbol, el baloncesto y el tenis son deportes muy populares a nivel global y cuentan con millones de seguidores!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oraci√≥n corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos √∫tiles, como si fueras un tutor.\\n                - S√© claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Quien es el jugador mas reconocido del tenis?\\n    '}, {'role': 'assistant', 'content': '¬°Sin duda, Roger Federer es una leyenda del tenis y uno de los atletas m√°s admirados en todo el mundo!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oraci√≥n corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos √∫tiles, como si fueras un tutor.\\n                - S√© claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Cuantos grand slams gano Roger?\\n    '}, {'role': 'assistant', 'content': '¬°Roger Federer ha ganado un impresionante total de 20 t√≠tulos de Grand Slam!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oraci√≥n corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos √∫tiles, como si fueras un tutor.\\n                - S√© claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Muchas por la informacion. Y quien fue su competidor mas fuerte?\\n    '}, {'role': 'assistant', 'content': '¬°Sin duda, Rafael Nadal ha sido uno de los rivales m√°s fuertes y emblem√°ticos de Federer en su carrera!'}]\n"
     ]
    }
   ],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e37-bf32-43b7-8958-e39954a20fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e1130-3106-4ce2-ab85-d05f63cb43a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209db13-f1b3-42a6-9268-78b51a3d6fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806ac48-0583-4b4a-9255-8d2ac6587960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
