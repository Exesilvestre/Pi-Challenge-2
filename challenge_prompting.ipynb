{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oLzddANOIqbvK7TieI6rtnAgV0PkpvxNVGlfcqL5\n"
     ]
    }
   ],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='492d5e7e-8ea7-4790-8b04-a167026aef0b' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "## bloque conexion a Cohere\n",
    "import cohere\n",
    "\n",
    "# co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisión\n",
    "- Síntomas\n",
    "- Diagnóstico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "example_text =\"\"\"La paciente, María González, de 45 años, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a síntomas de fatiga crónica y dolores musculares./\n",
    "Tras una serie de análisis, se diagnosticó fibromialgia. La doctora a cargo, Laura Ramírez, recomendó un tratamiento basado en fisioterapia y medicamentos analgésicos. /\n",
    "La próxima consulta está programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "example_response = {\n",
    "                      \"paciente\": {\n",
    "                        \"nombre\": \"María González\",\n",
    "                        \"edad\": 45\n",
    "                      },\n",
    "                      \"fecha_admision\": \"2023-08-05\",\n",
    "                      \"sintomas\": [\n",
    "                        \"fatiga crónica\",\n",
    "                        \"dolores musculares\"\n",
    "                      ],\n",
    "                      \"diagnostico\": \"fibromialgia\",\n",
    "                      \"tratamiento\": [\n",
    "                        \"fisioterapia\",\n",
    "                        \"medicamentos analgésicos\"\n",
    "                      ]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d0a6-db5c-4eec-9f71-89e60ceaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Sofía López, de 28 años, ingresó al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Después de varias pruebas, se le diagnosticó neumonía. La pediatra responsable, Dra. Claudia Torres, indicó tratamiento con antibióticos y reposo./\n",
    "La próxima evaluación será el 10 de abril.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "system_prompt = \"Sos un asistente de IA que dedicado para extraer de un texto ciertas entidades y devolverlas en formato Json\"\n",
    "def create_prompt(context):\n",
    "    prompt = f\"\"\" \n",
    "                ###\n",
    "                Instrucciones: \n",
    "                - Responde la pregunta utilizado el contexto.\n",
    "                - La respuesta debe estar estrictamente en formato JSON válido.\n",
    "                - Las entidades deben ser como las del ejemplo.\n",
    "                - Si hay algun dato que no este en el contexto debes dejarlo como null en el json.\n",
    "    \n",
    "                ###\n",
    "                Contexto:\n",
    "                {context}\n",
    "    \n",
    "                ###\n",
    "                Ejemplo:\n",
    "                {example_response}\n",
    "    \n",
    "                ###\n",
    "                Pregunta:\n",
    "                Obtenga desde el contexto las entidades paciente, fecha_admision, sintomas, diagnostico y tratamiento como en el ejemplo\n",
    "    \n",
    "                \"\"\"\n",
    "    return prompt\n",
    "    \n",
    "def extract_entities(context):\n",
    "    prompt = create_prompt(text_to_analize)\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Sofía López\",\n",
      "        \"edad\": 28\n",
      "    },\n",
      "    \"fecha_admision\": \"2023-04-03\",\n",
      "    \"sintomas\": [\"fiebre alta\", \"tos persistente\"],\n",
      "    \"diagnostico\": \"neumonía\",\n",
      "    \"tratamiento\": [\"antibióticos\", \"reposo\"]\n",
      "}\n",
      "{'paciente': {'nombre': 'Sofía López', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumonía', 'tratamiento': ['antibióticos', 'reposo']}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import json\n",
    "llm_response = extract_entities(prompt)\n",
    "print(llm_response)\n",
    "final_result = json.loads(llm_response)\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "097ee190-faca-46d8-9c11-0f8904bd1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prueba con mas descripciones\n",
    "text_to_analize_2 = \"\"\"Javier Morales, de 35 años, fue admitido en el Hospital General el 15 de mayo de 2023 debido a dolor abdominal severo y náuseas persistentes./\n",
    "Después de realizar una ecografía, se diagnosticó apendicitis aguda. El doctor encargado, Dr. Roberto Sánchez, indicó cirugía de emergencia seguida de reposo absoluto./\n",
    "La próxima revisión médica está programada para el 22 de mayo.\"\"\"\n",
    "\n",
    "text_to_analize3 = \"\"\"Ana Fernández, de 42 años, llegó al Hospital San Pedro el 10 de enero de 2023 con síntomas de dolor de cabeza intenso y visión borrosa./\n",
    "Tras un examen detallado, se le diagnosticó migraña crónica. La doctora a cargo, Dra. Mariana López, recomendó tratamiento con medicamentos específicos y sesiones de relajación./\n",
    "La próxima cita está fijada para el 17 de enero.\"\"\"\n",
    "\n",
    "text_to_analize_4 = \"\"\"Lucas Ramírez, de 50 años, ingresó al Hospital Universitario el 20 de marzo de 2023 debido a dificultad para respirar y dolor en el pecho./\n",
    "Después de varios estudios, se diagnosticó neumonía bacteriana. El médico tratante, Dr. Eduardo Gutiérrez, ordenó tratamiento con antibióticos intravenosos y oxigenoterapia./\n",
    "La siguiente consulta está prevista para el 27 de marzo.\"\"\"\n",
    "\n",
    "all_texts = [text_to_analize_2, text_to_analize3, text_to_analize_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df0e72e5-3bd5-4f26-860c-340e25e72f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TEST 1\n",
      "{'paciente': {'nombre': 'Sofía López', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumonía', 'tratamiento': ['antibióticos', 'reposo']}\n",
      "#### TEST 2\n",
      "{'paciente': {'nombre': 'Sofía López', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumonía', 'tratamiento': ['antibióticos', 'reposo']}\n",
      "#### TEST 3\n",
      "{'paciente': {'nombre': 'Sofía López', 'edad': 28}, 'fecha_admision': '2023-04-03', 'sintomas': ['fiebre alta', 'tos persistente'], 'diagnostico': 'neumonía', 'tratamiento': ['antibióticos', 'reposo']}\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "for test in all_texts:\n",
    "    try:\n",
    "        llm_response = extract_entities(test)\n",
    "        final_result = json.loads(llm_response)\n",
    "        print(f\"#### TEST {index}\")\n",
    "        print(final_result)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error al procesar TEST {index}: {e}\")\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan Pérez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): Número de teléfono del contacto.\n",
    "        email (str): Correo electrónico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adición del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto añadido con éxito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la información de un contacto.\n",
    "    Parámetros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Información del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\"\n",
    "\n",
    "functions_map = {\n",
    "    \"add_contact\": add_contact,\n",
    "    \"get_information\": get_information\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d3bed9a-d5d1-49c3-b91b-8cd23bb9c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Connects to a database to add a contact given his name, phone and email\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Add contact with this name.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Add contact with this phone number\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Add contact with this email address\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Connects a database to get a contact infromation given his name\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Retrieves contact information data the contact with that name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ddaf4d1-6ab9-4707-823d-11ada125b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "## Task and Context\n",
    "You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n",
    "You are able to interact with a contacts database.\n",
    "\n",
    "## Style Guide\n",
    "Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n",
    "\"\"\"\n",
    "add_contact_message1 = \"Agrega a Juan Pérez con el número 555-1234 y el correo juanperez@mail.com.\" \n",
    "add_contact_message2 = \"Guarda a Lucía Gómez en mis contactos. Su teléfono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "search_contact_info_message = \"Cual es el Email de Juan Pérez.?\"\n",
    "\n",
    "def create_messages(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will add the contact details provided to the database. \n",
      "\n",
      "Tool name: add_contact | Parameters: {\"email\":\"juanperez@mail.com\",\"name\":\"Juan Pérez\",\"phone\":\"555-1234\"}\n",
      "Contacto añadido con éxito.\n",
      "Final LLM Response: Contact added successfully.\n"
     ]
    }
   ],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "def llm_request(messages):\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def start_request(messages):\n",
    "    tool_content = []\n",
    "\n",
    "    # Call the model\n",
    "    response = llm_request(messages)\n",
    "    print(response.message.tool_plan, \"\\n\")\n",
    "\n",
    "    # Check if there are tool calls\n",
    "    if response.message.tool_calls:\n",
    "        for tc in response.message.tool_calls:\n",
    "            messages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})\n",
    "            # Access tool call attributes using dot notation\n",
    "            print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "            \n",
    "            # Call the suggested function\n",
    "            tool_result = functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "            tool_content.append(json.dumps(tool_result))\n",
    "            messages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': tool_content}) \n",
    "            print(tool_result)\n",
    "    else:\n",
    "        print(\"No function was called.\")\n",
    "\n",
    "    # Final LLM call to summarize the results\n",
    "    final_response = llm_request(messages)\n",
    "    print(\"Final LLM Response:\", final_response.message.content[0].text)\n",
    "\n",
    "messages = create_messages(add_contact_message1)\n",
    "start_request(messages)\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ace85d2-cd00-4bd4-81e2-68113eb9f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will add the contact details to the database. \n",
      "\n",
      "Tool name: add_contact | Parameters: {\"email\":\"lucia.gomez@gmail.com\",\"name\":\"Lucía Gómez\",\"phone\":\"555-5678\"}\n",
      "Contacto añadido con éxito.\n",
      "Final LLM Response: Hecho. He guardado a Lucía Gómez en tus contactos.\n"
     ]
    }
   ],
   "source": [
    "messages = create_messages(add_contact_message2)\n",
    "start_request(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c0a3461-981f-46ab-aded-314b016fffc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search for Juan Pérez in the database and then relay the email address to the user. \n",
      "\n",
      "Tool name: get_information | Parameters: {\"name\":\"Juan Pérez\"}\n",
      "{'phone': '555-1234', 'email': 'juanperez@mail.com'}\n",
      "Final LLM Response: The email address for Juan Pérez is juanperez@mail.com.\n"
     ]
    }
   ],
   "source": [
    "messages = create_messages(search_contact_info_message)\n",
    "start_request(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5edb99-ea7f-4e68-b1c2-3be0ce7d7798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instructions_lenguage = f\"\"\"\n",
    "    - Responde solo especificando el idioma en el que esta la pregunta\n",
    "    - La respuesta debe ser una sola palabra con el idioma.\n",
    "\"\"\"\n",
    "\n",
    "instructions = f\"\"\"\n",
    "    - las respuestas deben ser en base a la historia.\n",
    "    - ante la misma pregunta siempre debe responder de la misma manera.\n",
    "    - que responda en solo una oracion.\n",
    "    - el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "    - que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "    - que responda siempre en tercera persona.\n",
    "    - si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "    - Responder con 'Hakuna Matata!' al final de todas las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un pequeño feudo medieval, Thomas, un joven campesino de dieciséis años, trabajaba desde el amanecer en los campos de trigo del señor feudal. El sol apenas había salido cuando él ya había arado más de lo que sus manos podían soportar. La vida era dura, pero su familia dependía de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un día, el feudo fue sacudido por noticias de guerra. El rey había llamado a todos los hombres en edad de luchar. Thomas sabía que, al igual que otros jóvenes, no tenía elección. Cambió la hoz por una lanza rudimentaria y se unió a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el corazón latiendo en su pecho como un tambor de guerra, apenas podía distinguir amigo de enemigo. Logró esquivar una espada, pero cayó al suelo, cubierto de lodo y sangre. Levantándose, vio cómo un compañero caía junto a él, sus ojos abiertos, vacíos.\n",
    "\n",
    "Cuando la batalla terminó, el silencio era tan profundo como el vacío que sentía. Thomas regresó al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibió con lágrimas en los ojos, pero él, con la mirada fija en el horizonte, sabía que la inocencia había quedado atrás, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; él tampoco.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_prompt(instructions, pregunta, historia=\"\"):\n",
    "    prompt = f\"\"\" \n",
    "                ###\n",
    "                Instrucciones: \n",
    "                {instructions} \n",
    "                ###\n",
    "                Contexto:\n",
    "                {historia}\n",
    "    \n",
    "                ###\n",
    "                Pregunta:\n",
    "                {pregunta}\n",
    "    \n",
    "                \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "system_prompt = \"Sos un asistente de IA dedicado a responder consultas de usuarios de un amplio rango de temas. Te proveeran un contexto y el usuairo te hara preguntas sobre el mismo, en caso de poder repsonderlas debes elaborar una repsuesta de acuerdo al contexto.\"\n",
    "system_prompt1 = \"Sos un asistente de IA dedicado a responder el idioma en el que te preguntaron.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_request(messages):\n",
    "    response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    )\n",
    "    return response.message.content[0].text\n",
    "\n",
    "def create_messages(prompt, system_prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": prompt}]\n",
    "    return messages\n",
    "\n",
    "def determine_language(pregunta):\n",
    "    prompt = create_prompt(instructions_lenguage, pregunta)\n",
    "    messages = create_messages(prompt, system_prompt1)\n",
    "    return llm_request(messages)\n",
    "\n",
    "def generate_final_answer(pregunta, idioma):\n",
    "    final_instructions = f\"\"\"\n",
    "        {instructions}\n",
    "        - La respuesta debe estar en el idioma: {idioma}.\n",
    "    \"\"\"\n",
    "    prompt = create_prompt(final_instructions, pregunta, historia)\n",
    "    messages = create_messages(prompt, system_prompt)\n",
    "    return llm_request(messages)\n",
    "\n",
    "def history_answer(pregunta):\n",
    "    idioma = determine_language(pregunta)\n",
    "    return generate_final_answer(pregunta, idioma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b13663-c4d1-47b9-9c63-9d0015d2a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas tiene dieciséis años, una edad en la que la inocencia y la dureza de la vida se encuentran. 🌾 Hakuna Matata!\n",
      "Thomas se ve obligado a cambiar su hoz por una lanza y unirse a la milicia local debido al llamado a las armas del rey, quien convocó a todos los hombres en edad de luchar para la guerra, dejando atrás su dura pero pacífica vida de campesino. Hakuna Matata! 🗡️🌾🦁\n",
      "Thomas regresa al feudo con el corazón pesado, marcado por la cruda realidad de la guerra, sintiendo que la inocencia de su juventud ha sido arrebatada brutalmente, y su mirada fija en el horizonte refleja un vacío y una madurez forzada. 😞 Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "# respuesta\n",
    "preguntas = [\n",
    "    \"¿Cuál es la edad de Thomas?\",\n",
    "    \"¿Por qué Thomas se ve obligado a unirse a la milicia local?\",\n",
    "    \"¿Qué siente Thomas después de la batalla?\",\n",
    "    \"¿Qué es el sistema operativo Linux?\",\n",
    "    \"¿Cómo se construye un puente colgante?\"\n",
    "]\n",
    "for pregunta in preguntas:\n",
    "    print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "795f451e-6c12-4631-895f-fa6ac8f16b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas tiene dieciséis años y trabaja desde el amanecer en los campos de trigo. 🌾 Hakuna Matata!\n",
      "Thomas se ve obligado a cambiar su hoz por una lanza y unirse a la milicia local debido al llamado a las armas del rey, quien convocó a todos los hombres en edad de luchar para la guerra, dejando atrás su dura pero pacífica vida campesina. Hakuna Matata! 🗡️🌾🦁\n",
      "Thomas regresó al feudo con el corazón pesado, marcado por la brutal realidad de la guerra, sintiendo que la inocencia de su juventud había quedado enterrada en ese campo de batalla, junto con los caídos. 😞 Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con eso. Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "# Chequeo de que siempre repsonde lo mismo ante las mismas preguntas\n",
    "preguntas = [\n",
    "    \"¿Cuál es la edad de Thomas?\",\n",
    "    \"¿Por qué Thomas se ve obligado a unirse a la milicia local?\",\n",
    "    \"¿Qué siente Thomas después de la batalla?\",\n",
    "    \"¿Qué es el sistema operativo Linux?\",\n",
    "    \"¿Cómo se construye un puente colgante?\"\n",
    "]\n",
    "for pregunta in preguntas:\n",
    "    print(history_answer(pregunta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos útiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7daa9f9-e5f4-4273-8b8d-66088e816f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f3dfe3e30842e39ee0a083a241952d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aquí...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eba16455e244ff3ac3b4232bde321cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bff4e6d73f748629073f71891320407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aquí...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "instructions = f\"\"\"\n",
    "                - Responder con una sola oración corta.\n",
    "                - Responder de manera positiva, con un tono entusiasta.\n",
    "                - Responder con consejos útiles, como si fueras un tutor.\n",
    "                - Sé claro y conciso.\n",
    "                - La respuesta deber tener menos de 70 tokens\"\"\"\n",
    "\n",
    "system_content = \"\"\"\n",
    "        Eres un chatbot diseñado para ayudar y dar consejos útiles.\n",
    "        Siempre debes ser positivo, con un tono entusiasta, y tus respuestas deben ser concisas y claras.\n",
    "        Tu objetivo es ayudar de manera efectiva y siempre dentro del límite de 70 tokens.\n",
    "\n",
    "    \"\"\"\n",
    "def create_prompt(instructions, pregunta):\n",
    "    prompt = f\"\"\" \n",
    "    ###\n",
    "    Instrucciones: \n",
    "    {instructions}\n",
    "    ###\n",
    "    Pregunta:\n",
    "    {pregunta}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "    \n",
    "chat_history = []\n",
    "\n",
    "# Función de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    prompt = create_prompt(instructions, message)\n",
    "\n",
    "    relevant_history = chat_history[-3:]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content}\n",
    "    ]\n",
    "    messages.extend(relevant_history) \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt}) \n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=messages,\n",
    "        max_tokens=70\n",
    "    )\n",
    "    text_response = response.message.content[0].text\n",
    "    print(response.usage.billed_units)\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": text_response})\n",
    "    \n",
    "    return text_response\n",
    "\n",
    "# Función de manejo del botón\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"Tú: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar función al botón\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d5bce-0189-4ecd-a06d-fcc7a81315b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d22e77e-3784-4443-8d89-a3156adca812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tú:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oración corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos útiles, como si fueras un tutor.\n",
      "                - Sé claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Hola como estas?\n",
      "    \n",
      "\n",
      "Chatbot: ¡Hola! Estoy genial y listo para ayudarte con cualquier duda o desafío que tengas. ¡Pregunta sin miedo!\n",
      "\n",
      "Tú:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oración corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos útiles, como si fueras un tutor.\n",
      "                - Sé claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Cuales son los tres deportes mas famosos del mundo?\n",
      "    \n",
      "\n",
      "Chatbot: ¡El fútbol, el baloncesto y el tenis son deportes muy populares a nivel global y cuentan con millones de seguidores!\n",
      "\n",
      "Tú:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oración corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos útiles, como si fueras un tutor.\n",
      "                - Sé claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Quien es el jugador mas reconocido del tenis?\n",
      "    \n",
      "\n",
      "Chatbot: ¡Sin duda, Roger Federer es una leyenda del tenis y uno de los atletas más admirados en todo el mundo!\n",
      "\n",
      "Tú:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oración corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos útiles, como si fueras un tutor.\n",
      "                - Sé claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Cuantos grand slams gano Roger?\n",
      "    \n",
      "\n",
      "Chatbot: ¡Roger Federer ha ganado un impresionante total de 20 títulos de Grand Slam!\n",
      "\n",
      "Tú:  \n",
      "    ###\n",
      "    Instrucciones: \n",
      "    \n",
      "                - Responder con una sola oración corta.\n",
      "                - Responder de manera positiva, con un tono entusiasta.\n",
      "                - Responder con consejos útiles, como si fueras un tutor.\n",
      "                - Sé claro y conciso.\n",
      "                - La respuesta deber tener menos de 70 tokens\n",
      "    ###\n",
      "    Pregunta:\n",
      "    Muchas por la informacion. Y quien fue su competidor mas fuerte?\n",
      "    \n",
      "\n",
      "Chatbot: ¡Sin duda, Rafael Nadal ha sido uno de los rivales más fuertes y emblemáticos de Federer en su carrera!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_conversation(chat_history):\n",
    "    for message in chat_history:\n",
    "        if message['role'] == 'user':\n",
    "            print(f\"Tú: {message['content']}\\n\")\n",
    "        elif message['role'] == 'assistant':\n",
    "            print(f\"Chatbot: {message['content']}\\n\")\n",
    "\n",
    "# Imprimir el chat\n",
    "print_conversation(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oración corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos útiles, como si fueras un tutor.\\n                - Sé claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Hola como estas?\\n    '}, {'role': 'assistant', 'content': '¡Hola! Estoy genial y listo para ayudarte con cualquier duda o desafío que tengas. ¡Pregunta sin miedo!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oración corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos útiles, como si fueras un tutor.\\n                - Sé claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Cuales son los tres deportes mas famosos del mundo?\\n    '}, {'role': 'assistant', 'content': '¡El fútbol, el baloncesto y el tenis son deportes muy populares a nivel global y cuentan con millones de seguidores!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oración corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos útiles, como si fueras un tutor.\\n                - Sé claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Quien es el jugador mas reconocido del tenis?\\n    '}, {'role': 'assistant', 'content': '¡Sin duda, Roger Federer es una leyenda del tenis y uno de los atletas más admirados en todo el mundo!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oración corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos útiles, como si fueras un tutor.\\n                - Sé claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Cuantos grand slams gano Roger?\\n    '}, {'role': 'assistant', 'content': '¡Roger Federer ha ganado un impresionante total de 20 títulos de Grand Slam!'}, {'role': 'user', 'content': ' \\n    ###\\n    Instrucciones: \\n    \\n                - Responder con una sola oración corta.\\n                - Responder de manera positiva, con un tono entusiasta.\\n                - Responder con consejos útiles, como si fueras un tutor.\\n                - Sé claro y conciso.\\n                - La respuesta deber tener menos de 70 tokens\\n    ###\\n    Pregunta:\\n    Muchas por la informacion. Y quien fue su competidor mas fuerte?\\n    '}, {'role': 'assistant', 'content': '¡Sin duda, Rafael Nadal ha sido uno de los rivales más fuertes y emblemáticos de Federer en su carrera!'}]\n"
     ]
    }
   ],
   "source": [
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e37-bf32-43b7-8958-e39954a20fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e1130-3106-4ce2-ab85-d05f63cb43a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209db13-f1b3-42a6-9268-78b51a3d6fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806ac48-0583-4b4a-9255-8d2ac6587960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
